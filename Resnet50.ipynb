{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Import python3 libaries\n",
    "1. Download the Kaggle dataset on stanford-car-parks\n",
    "1. Set up the files for experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/ngailam_ho/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2\n",
      "PATH : /home/ngailam_ho/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2\n",
      "mv: cannot stat '/home/ngailam_ho/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2/car_data/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jutrera/stanford-car-dataset-by-classes-folder\")\n",
    "PATH = path\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "print(f\"PATH : {PATH}\")\n",
    "\n",
    "! rm -rf  ~/content/\n",
    "! mkdir ~/content/\n",
    "! mv -v {PATH}/car_data/*   ~/content/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "! ls -l /home/ngailam_ho/content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "classes_path = \"/root/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2/car_data/car_data\"\n",
    "\n",
    "train_annos_path = classes_path\n",
    "test_annos_path = classes_path\n",
    "#classes_path = 'devkit/cars_meta.mat' names.csv\n",
    "#classes_path = \"/root/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2/car_data/car_data\"\n",
    "\n",
    "def get_labels(annos_path, classes_path):\n",
    "    car_annos = sio.loadmat(path + annos_path)\n",
    "    car_meta = sio.loadmat(path + classes_path)\n",
    "    annotations = car_annos[\"annotations\"][0,:]\n",
    "    nclasses = len(car_meta[\"class_names\"][0])\n",
    "    class_names = dict(zip(range(1,nclasses),[c[0] for c in car_meta[\"class_names\"][0]]))\n",
    "\n",
    "    labelled_images = {}\n",
    "    dataset = []\n",
    "    for i,arr in enumerate(annotations):\n",
    "        # the last entry in the row is the image name\n",
    "        # The rest is the data, first bbox, then classid\n",
    "        dataset.append([y[0][0] for y in arr][0:5]+[arr[5][0]])\n",
    "    # Convert to a DataFrame, and specify the column names\n",
    "    temp_df = pd.DataFrame(dataset,\n",
    "                      columns =['BBOX_X1','BBOX_Y1','BBOX_X2','BBOX_Y2','ClassID','filename'])\n",
    "\n",
    "    temp_df = temp_df.assign(ClassName=temp_df.ClassID.map(dict(class_names)))\n",
    "    temp_df.columns = ['bbox_x1','bbox_y1','bbox_x2','bbox_y2','class_id','filename', 'class_name']\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    model=model.to('cuda')\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "             # forward + backward + optimize\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %0.2f %%' % (test_acc))\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA : cuda:0\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "root : ../StanfordCars/data/stanford-cars-dataset/data/car_data/car_data//train \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using CUDA : {device}\")\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = \"../StanfordCars/data/stanford-cars-dataset/data/car_data/car_data/\"\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "print(f\"root : {dataset_dir}/train \")\n",
    "dataset = torchvision.datasets.ImageFolder(root = f\"{dataset_dir}/\",\n",
    "                                           transform = train_tfms)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 32,\n",
    "                                          shuffle=True, num_workers = 2)\n",
    "\n",
    "dataset2 = torchvision.datasets.ImageFolder(root =  f\"{dataset_dir}/\",\n",
    "                                            transform = test_tfms)\n",
    "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 32,\n",
    "                                         shuffle=False, num_workers = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngailam_ho/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ngailam_ho/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 291 s, loss: 0.6814, acc: 60.5463\n",
      "Accuracy of the network on the test images: 62.52 %\n",
      "Epoch 2, duration: 294 s, loss: 0.5910, acc: 62.6238\n",
      "Accuracy of the network on the test images: 63.13 %\n",
      "Epoch 3, duration: 294 s, loss: 0.5784, acc: 62.5133\n",
      "Accuracy of the network on the test images: 63.08 %\n",
      "Epoch 4, duration: 295 s, loss: 0.5669, acc: 62.6459\n",
      "Accuracy of the network on the test images: 63.38 %\n",
      "Epoch 5, duration: 295 s, loss: 0.5558, acc: 62.8006\n",
      "Accuracy of the network on the test images: 63.50 %\n",
      "Epoch 6, duration: 295 s, loss: 0.5240, acc: 63.5962\n",
      "Accuracy of the network on the test images: 63.95 %\n",
      "Epoch 7, duration: 295 s, loss: 0.5167, acc: 63.4017\n",
      "Accuracy of the network on the test images: 64.10 %\n",
      "Epoch 8, duration: 295 s, loss: 0.5117, acc: 63.9675\n",
      "Accuracy of the network on the test images: 64.19 %\n",
      "Epoch 9, duration: 295 s, loss: 0.5072, acc: 63.8879\n",
      "Accuracy of the network on the test images: 64.21 %\n",
      "Epoch 10, duration: 294 s, loss: 0.5029, acc: 64.3343\n",
      "Accuracy of the network on the test images: 64.17 %\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3767748/3978349732.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, (inputs, classes) in tqdm_notebook( enumerate(testloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4a5ec9e5c44cc831d164d0f471793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1881.,  740., 5429.,  ...,    0.,    0.,    0.],\n",
      "        [ 137., 2159., 4219.,  ...,    0.,    0.,    0.],\n",
      "        [1890.,  766., 5394.,  ...,    0.,    0.,    0.],\n",
      "        ...,\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.]])\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01,momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold=0.9)\n",
    "\n",
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=10)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "nb_classes = 196\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in tqdm_notebook( enumerate(testloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE MODEL\n",
    "torch.save(model_ft.state_dict(), 'Rasnet50.pth')\n",
    "\n",
    "#model_json = model_ft.to_json()\n",
    "#with open(\"model_arch.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# model = YourModel()  # Create an instance of your model\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# model_ft = models.resnet50(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "# model.load_state_dict(torch.load('model_ft.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ngailam_ho ngailam_ho 95955971 Nov 24 23:26 Rasnet50.pth\n"
     ]
    }
   ],
   "source": [
    "! ls -l Rasnet50*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 31559,
     "sourceId": 46697,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30302,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
